#### 系统目标     
      主要是针对应用场景生产和消费消息的时候做的一些封装，开源也有一些入Spring的继承封装；所以尝试自己取实现一个这样的组件。
      1.动态创建, 销毁消费者任务,对消费任务进行自动化管理
      2.可以结合实际生产情况对任务进行管理,解决一些需要按offset消费的任务
      3.对任务限流按流量字节大小,数据量进行限流目的是为了任务持续稳定执行,在资源紧张的时候可以适当的进行限流降低程序压力,
         按byte大小更有意义
      4.对消费者任务的度量,比如根据当前任务消费的record计算任务线程的EPS实时监控消费者的压力
      5.在进行动态扩展分区的时候,能结合任务动态创建按资源进行适当增加消费者
    
      功能架构设计：
       1.将每一组的的线程执行任务抽象成一个Job,在Job下面有多个consumer的设计
       2.Job中可以对每个Consumer消费的Topic的分区的指定初始化
       3.通过Job定义Job去初始化consumer,JobConsumer是一组消费线程的管理实现
       4.通过事件分发机制去管理consumer的消费情况
       
     针对单机部署的应用，那么是否需要支持简单的分布式操作呢？
     这个只是提供一个基础的API包，并不是一个任务系统框架；所以采取的设计只是API的方式。
     只是为了方便开发、解决实际应用中需要解决的一些问题：
     1.设计对任务的管理主要是能将KAFKA的消费功能进行统一的抽象，用户只需要关注自己的业务逻辑。消费任务的创建、管理、运行、销毁交给
       API层面去解决。
     2.任务的高可用性、即任务的容错采取怎样的方式解决，任务失败重启（环境错误、可恢复错误、不可恢复错误）、应用系统的容错
     3.任务状态的监控、例如长时间未能从kafka消费到数据是否该告警。offset监控、ISR同步列表的监控
     4.
     
     
     容错设计：
     概要：容错一般也要结合系统设计架构去考虑容错，容错这个还是很有讲究的，容错的机制:FailedFast、FailedOver、FailedSafe等可能是程序
           容错。容错目的是保障数据可靠性、程序状态正确性、系统可用性等;那么从系统角度来看,主要是保证数据从进入系统到出系统整个过程中
           的一致性。
           那么常规的手段有哪些方式保障一致性：
           数据从系统A进入系统B：
           1.系统B支持数据的commit或WAL操作，也就是标记着该数据已经持久化了，此时返回ACK给A系统，但是一般这个时候逐条的写入，带来
             TPS比较低、所以需要在数据一致性和TPS之间进行取舍。也有同步或者异步返回ACK
           2. 系统B支持幂等特性、在不丢失数据的情况下但存在重复处理的时候也不会影响业务正常性、也是保障数据一致性的一种方式需要在B端进行实现           
           3. 系统A、B各自内部数据状态的保障
           
           上述只是简单描述一些场景保障数据安全性、但实际应用中需要结合系统给架构设计、系统目标背景等去考虑数据安全性；也就是结合
           系统特性去考虑容错，列举一些常见的系统：
           Doubbo,Flink、Bookkeeper、Kafka的系统数据一致性和容错性是怎么设计的考虑的，都是不尽相同的。
          
           
                         
     
       